# 데이터 확인
plot(df_t2$Tsq_mat, type = 'o', ylim = c(0,600))
# t square으로 나온 limit plot
abline(h = c(df_t2$CL), col = 'red')
df_t2 = t_square(df_tr, df_tr, 0.05)
plot(df_t2_2$Tsq_mat, type = 'l', ylim = c(0,700), xlab = 'time', ylab = 'T-square')
# t square으로 나온 limit plot
abline(h = c(df_t2$CL), col = 'red')
t_square
t2_solve = t_square_solve(df_tr, te, i/1000)
s1_solve = t_square_solve(df_tr, df_tr, i/1000)
plot(mat[,2:3], xlab = 'alpha error', ylab = 'beta error', main = '유의 수준에 따른 error') # hostelling t-square ginv 진행
points(mat2[,2:3],col='green',type='o') # cbm ginv 진행
points(mat3[,2:3],col='blue',type='o') # hostelling t-square solve 진행
points(mat4[,2:3],col='red',type='o') # cbm solve 진행
legend('topright', legend = c('t-square ginv','cbm ginv','t-square solve','cbm solve'), fill =  c('black', 'green','blue','red'))
abline(v=c(50),col='blue',lwd=3)
plot(ir_t2$Tsq_mat,type='o')
abline(h=c(ir_t2$CL),col='red')
abline(v=c(50),col='blue',lwd=3)
library(rgl)
library(ggbiplot)
library(ggplot2)
library(corrplot)
g
g1
library(plotly)
plot3d(q_mat[,2],q_mat[,3],q_mat[,4],
col = cols[as.factor(q_mat$V1)],
xlab = 'pc1',
ylab = 'pc2',
zlab = 'pc3',
)
q_mat$V1
g = ggbiplot(pc2, choices = c(1,2), obs.scale = 1, var.scale = 1, ellipse = TRUE, circle = TRUE )
g = g + scale_color_discrete(name="")
g = g + theme(legend.direction = 'horizontal', legend.position = 'top')
g
k = ggbiplot(pc, choices = c(1,2), obs.scale = 1, var.scale = 1, ellipse = TRUE, circle = TRUE )
k = k + scale_color_discrete(name="")
k = k + theme(legend.direction = 'horizontal', legend.position = 'top')
k
plot(x,y) # pca해서 2차원 표현
= df[,8:49] # 필요 정보만 select
df_tr= df[,8:49] # 필요 정보만 select
df_tr = df[,8:49] # 필요 정보만 select
df_te = df2[,8:49] # 필요 정보만 select
df_te_2 = df3[,8:49] # 필요 정보만 select
te = rbind(df_te, df_te_2)
df_test = df[,8:49] # PCA set
df_test2 = df[,8:49] # Normalization PCA set
df_test = df[,8:49] # PCA set
cor(df_test) # 상관관계
corrplot(cor(df_test))
library(corrplot)
corrplot(cor(df_test))
corrplot.mixed(cor(df_test), upper = 'shade')
corrplot(cor(ir))
corrplot(cor(df_test))
corrplot(cor(df_test), labels = c(1,2,3))
cor(df_test) # 상관관계
corrplot.mixed(cor(df_test), upper = 'shade')
corrplot(cor(df_test), labels = c(1:41))
corrplot(cor(df_test), cl.pos = 'n', tl.pos = 'n')
corrplot(cor(df_test),order = 'AOE' cl.pos = 'n', tl.pos = 'n')
corrplot(cor(df_test),order = 'AOE', cl.pos = 'n', tl.pos = 'n')
corrplot.mixed(cor(df_test),order = 'AOE', cl.pos = 'n', tl.pos = 'n')
corrplot.mixed(cor(df_test), cl.pos = 'n', tl.pos = 'n')
##
cor.mtest <- function(mat, conf.level = 0.95) {
mat <- as.matrix(mat)
n <- ncol(mat)
p.mat <- lowCI.mat <- uppCI.mat <- matrix(NA, n, n)
diag(p.mat) <- 0
diag(lowCI.mat) <- diag(uppCI.mat) <- 1
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
tmp <- cor.test(mat[, i], mat[, j], conf.level = conf.level)
p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
lowCI.mat[i, j] <- lowCI.mat[j, i] <- tmp$conf.int[1]
uppCI.mat[i, j] <- uppCI.mat[j, i] <- tmp$conf.int[2]
}
}
return(list(p.mat, lowCI.mat, uppCI.mat))
}
res1 <- cor.mtest(df_test, 0.95)
res1
res2 <- cor.mtest(df_test, 0.99)
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
corrplot(M, p.mat = res1[[1]], sig.level = 0.2)
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
corrplot(df_test, p.mat = res1[[1]], sig.level = 0.2)
res1[[1]]
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
corrplot(df_test, p.mat = res1[[1]], sig.level = 0.2)
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
corrplot(df_test, p.mat = res1[[1]], sig.level = 0.5)
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
corrplot(df_test, p.mat = res1[[1]], sig.level = 0.05)
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
corrplot(cov(df_test), p.mat = res1[[1]], sig.level = 0.05)
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
corrplot(cor(df_test), p.mat = res1[[1]], sig.level = 0.05)
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
corrplot(cor(df_test), p.mat = res1[[1]], sig.level = 0.05, cl.pos = 'n', tl.pos = 'n' )
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
corrplot(cor(df_test), p.mat = res1[[1]], sig.level = 0.2, cl.pos = 'n', tl.pos = 'n' )
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
corrplot(cor(df_test), p.mat = res1[[1]], sig.level = 0.2, cl.pos = 'n' )
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
corrplot(cor(df_test), p.mat = res1[[1]], sig.level = 0.2 )
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
plot.new()
corrplot(cor(df_test), p.mat = res1[[1]], sig.level = 0.2 )
dev.off()
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
png(paste0("TFT cor plot.png"))
corrplot(cor(df_test), p.mat = res1[[1]], sig.level = 0.2 )
res1[[1]]
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
png(paste0("TFT cor plot.png"))
corrplot(cor(df_test), p.mat = res1[[1]], sig.level = 0.2 )
dev.off()
corrplot(cor(df_test), p.mat = res1[[1]], sig.level = 0.2 )
res1 <- cor.mtest(df_test, 0.95)
res2 <- cor.mtest(df_test, 0.99)
res1
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
cor_test_mat = coor.test(df_test)
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
cor_test_mat = corr.test(df_test)
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
library('pshch')
## 유의수준에 따라 유의하지 않은 경우 X 표시하기
install.packages('psych')
library(pshch)
library(psych)
cor_test_mat = corr.test(df_test)
corrplot(cor(df_test), p.mat = cor_test_mat, sig.level = 0.2 )
corr.test(df_test)
cor_test_mat = corr.test(df_test)$p
cor_test_mat
corrplot(cor(df_test), p.mat = cor_test_mat, sig.level = 0.2 )
corrplot(cor(df_test), p.mat = cor_test_mat, insig = 'p-value' )
dev.off()
corrplot(cor(df_test), p.mat = cor_test_mat, cl.pos = 'n', tl.pos = 'n' )
dev.off()
png(paste0("TFT cor plot.png"))
corrplot(cor(df_test), p.mat = cor_test_mat, cl.pos = 'n', tl.pos = 'n' )
dev.off()
png(paste0("TFT cor plot_1.png"))
corrplot(cor(df_test), cl.pos = 'n', tl.pos = 'n' )
dev.off()
#png(paste0("TFT cor plot_1.png"))
corrplot(cor(df_test), p.mat = cor_test_mat, cl.pos = 'n', tl.pos = 'n' )
corrplot(cor(df_test), cl.pos = 'n', tl.pos = 'n' )
corrplot(cor(df_test), cl.pos = 1:41, tl.pos = 'n' )
corrplot(cor(df_test), cl.pos = 'a', tl.pos = 'n' )
corrplot(cor(df_test), cl.pos = 'n', tl.pos = 'n' )
corrplot(cor(df_test),method = 'number', cl.pos = 'n', tl.pos = 'n' )
te[,1]
nrow(df_tr)
ncol(df_tr)
df_tr[,1]
colnames(df_tr)
colnames(df_tr)[1]
setwd('C:\\Users\\User\\github\\Rstudio\\Project')
for (i in 1:42) {
train = df_tr[,i]
test = te[,i]
msetLR = mset_regress(train, test)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("sensor ",colnames(df_tr)[i],".png"))
plot(tsDegradation)
dev.off()
}
for (i in 1:42) {
train = as.matrix(df_tr[,i])
test = as.matrix(te[,i])
msetLR = mset_regress(train, test)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("sensor ",colnames(df_tr)[i],".png"))
plot(tsDegradation)
dev.off()
}
library(pracma)
for (i in 1:42) {
train = as.matrix(df_tr[,i])
test = as.matrix(te[,i])
msetLR = mset_regress(train, test)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("sensor ",colnames(df_tr)[i],".png"))
plot(tsDegradation)
dev.off()
}
library(MASS)
for (i in 1:42) {
train = as.matrix(df_tr[,i])
test = as.matrix(te[,i])
msetLR = mset_regress(train, test)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("sensor ",colnames(df_tr)[i],".png"))
plot(tsDegradation)
dev.off()
}
degradation_model = function(residual){
Comment = "
@Description
Degradation Factor
Degradation Factor is used to transformed Anomaly scores and applied to predict Remaining Useful Lifecycle
@Param
anomalyScore : anomalyScore
@Return
degradation statistics
"
residual = as.matrix(residual)
# residual euclidean norm
residual_ed_norm = matrix(0, nrow(residual), ncol(residual))
for(i in 1:ncol(residual)){
residual_ed_norm[,i] =  sqrt(residual[,i]^2)
}
# accumulated degradation model
accum_degradation = matrix(0, nrow(residual), ncol(residual))
for(i in 1:ncol(residual)){
accum_degradation[,i] =  cumsum(residual_ed_norm[,i])
}
# degradation model
n = 1:nrow(residual)
degradation = matrix(0, nrow(residual), ncol(residual))
for(i in 1:ncol(residual)){
degradation[,i] =  cumsum(residual_ed_norm[,i])/n
}
return(degradation)
}
for (i in 1:42) {
train = as.matrix(df_tr[,i])
test = as.matrix(te[,i])
msetLR = mset_regress(train, test)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("sensor ",colnames(df_tr)[i],".png"))
plot(tsDegradation)
dev.off()
}
te
all = rbind(df_tr, te)
all
for (i in 1:42) {
train = as.matrix(df_tr[,i])
test = as.matrix(all[,i])
msetLR = mset_regress(train, test)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("sensor ",colnames(df_tr)[i]," all.png"))
plot(tsDegradation)
dev.off()
}
df1 = read.csv("C:\\Users\\User\\github\\data\\TFTLCD\\Tool1_all.csv", fileEncoding = 'CP949')
df2 = read.csv("C:\\Users\\User\\github\\data\\TFTLCD\\Tool2_all.csv", fileEncoding = 'CP949')
df3 = read.csv("C:\\Users\\User\\github\\data\\TFTLCD\\Tool3_all.csv", fileEncoding = 'CP949')
df1 = read.csv("C:\\Users\\User\\github\\data\\TFTLCD\\Tool1_all.csv")
df1 = read.csv("C:\\Users\\User\\github\\Rstudio\\Project\\Tool1_all.csv",, fileEncoding = 'CP949')
df2 = read.csv("C:\\Users\\User\\github\\Rstudio\\Project\\Tool2_all.csv", fileEncoding = 'CP949')
df3 = read.csv("C:\\Users\\User\\github\\Rstudio\\Project\\Tool3_all.csv", fileEncoding = 'CP949')
df4 = read.csv("C:\\Users\\User\\github\\Rstudio\\Project\\Tool4_all.csv", fileEncoding = 'CP949')
nrow(df1)
ncol(df1)
df1[1:636,2:43]
df1_train = df1[1:636,2:43] # tool1 정상 구간
df2_train = df2[1:398,2:43] # tool1 정상 구간
df3_train = df3[1:574,2:43] # tool1 정상 구간
df4_train = df4[1:391,2:43] # tool1 정상 구간
df1_train = df1[636:,2:43] # tool1 정상 구간
df1
nrow(df1)
df1_train = df1[636:nrow(df1),2:43] # tool1 정상 구간
df1_train = df1[637:nrow(df1),2:43] # tool1 정상 구간
df2_train = df2[399:nrow(df2),2:43] # tool1 정상 구간
df3_train = df3[575:nrow(df3),2:43] # tool1 정상 구간
df4_train = df4[392:nrow(df4),2:43] # tool1 정상 구간
df1_train = df1[1:636,2:43] # tool1 정상 구간
df2_train = df2[1:398,2:43] # tool1 정상 구간
df3_train = df3[1:574,2:43] # tool1 정상 구간
df4_train = df4[1:391,2:43] # tool1 정상 구간
df1_test = df1[637:nrow(df1),2:43] # tool1 정상 구간
df2_test = df2[399:nrow(df2),2:43] # tool1 정상 구간
df3_test = df3[575:nrow(df3),2:43] # tool1 정상 구간
df4_test = df4[392:nrow(df4),2:43] # tool1 정상 구간
ncol(df1_test)
setwd('C:\\Users\\User\\github\\Rstudio\\Project\\TFT_Degradation_plot_tool')
de = function(train, test){
for (i in 1:42) {
train = as.matrix(train[,i])
test = as.matrix(test[,i])
msetLR = mset_regress(train, test)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("sensor ",colnames(df_tr)[i]," all.png"))
plot(tsDegradation)
dev.off()
}
}
de(df1_test,df1_train)
library(pracma)
library(MASS)
de(df1_test,df1_train)
df1_test[,1]
de(df1_test,df1_train)
df1_train[,1]
de(df1_test,df1_train)
df1_train[,42]
df1_train[,43]
df1_train[,41]
typeof(df1_train[,1])
df1_train[,2]
df1_train[,2]
de(df1_test,df1_train)
de(df1_train,df1_test)
df1_train
df1_test
df1_train
nrow(df1_test)
ncol(df1_test)
ncol(df1_train)
de = function(train, test){
for (i in 1:42) {
train_ = as.matrix(train[,i])
test_ = as.matrix(test[,i])
msetLR = mset_regress(train_, test_)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("tool 1 sensor ",colnames(df_tr)[i]," all.png"))
plot(tsDegradation)
dev.off()
}
}
de(df1_train,df1_test)
de(df2_train,df2_test)
de = function(train, test){
for (i in 1:42) {
train_ = as.matrix(train[,i])
test_ = as.matrix(test[,i])
msetLR = mset_regress(train_, test_)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("tool 1 sensor ",colnames(df_tr)[i]," all.png"))
plot(tsDegradation)
dev.off()
}
}
de(df1_train,df1_test)
de = function(train, test){
for (i in 1:42) {
train_ = as.matrix(train[,i])
test_ = as.matrix(test[,i])
msetLR = mset_regress(train_, test_)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("tool 2 sensor ",colnames(df_tr)[i]," all.png"))
plot(tsDegradation)
dev.off()
}
}
de(df2_train,df2_test)
de = function(train, test){
for (i in 1:42) {
train_ = as.matrix(train[,i])
test_ = as.matrix(test[,i])
msetLR = mset_regress(train_, test_)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("tool 3 sensor ",colnames(df_tr)[i]," all.png"))
plot(tsDegradation)
dev.off()
}
}
de(df3_train,df3_test)
de = function(train, test){
for (i in 1:42) {
train_ = as.matrix(train[,i])
test_ = as.matrix(test[,i])
msetLR = mset_regress(train_, test_)
trDegradation = degradation_model(msetLR$residual_tr)
tsDegradation = degradation_model(msetLR$residual_ts)
png(paste0("tool 4 sensor ",colnames(df_tr)[i]," all.png"))
plot(tsDegradation)
dev.off()
}
}
de(df4_train,df4_test)
df1_test
df2_test
df1_test
cumsum
summary(df1_test)
df = read.csv("C:\\Users\\User\\github\\data\\TFTLCD\\ph1_bytime.csv", fileEncoding = 'CP949') # train
df2 = read.csv("C:\\Users\\User\\github\\data\\TFTLCD\\ph2_in.csv", fileEncoding = 'CP949') # normal test
df3 = read.csv("C:\\Users\\User\\github\\data\\TFTLCD\\ph2_out.csv", fileEncoding = 'CP949') # abnormal test
df_tr = df[,8:49] # 필요 정보만 select
df_te = df2[,8:49] # 필요 정보만 select
df_te_2 = df3[,8:49] # 필요 정보만 select
df2[df2$TOOL_NAME == 'P8TCVD060306','TOOL_NAME'] = 'Tool1'
df2[df2$TOOL_NAME == 'P8TCVD060307','TOOL_NAME'] = 'Tool2'
df2[df2$TOOL_NAME == 'P8TCVD060308','TOOL_NAME'] = 'Tool3'
df2[df2$TOOL_NAME == 'P8TCVD060309','TOOL_NAME'] = 'Tool4'
te = rbind(df_te, df_te_2)
all = rbind(df_tr, te)
all = cbind(df2[,1],all)
df2
all = cbind(df2[,6],all)
head(all)
head(all)
df2[,6]
df2
all = rename(all,c('df2[, 1]' = 'TIME_STAMP'))
all = rename(all,c('df2[, 2]' = 'TOOL_NAME'))
all = rename(all,c('df2[, 2]' = 'TOOL_NAME'))
all = rename(all,c('df2[, 1]' = 'TIME_STAMP'))
rename(all,c('df2[, 2]' = 'TOOL_NAME'))
## DegradationModel 적용후
## 열화정도 plot
library(pracma)
library(MASS)
all = rename(all,c('df2[, 2]' = 'TOOL_NAME'))
all = rename(all,c('df2[, 2]' = 'TOOL_NAME'))
library(reshape)
install.packages('reshape')
library(reshape)
all = rename(all,c('df2[, 2]' = 'TOOL_NAME'))
all = rename(all,c('df2[, 1]' = 'TIME_STAMP'))
all
df = read.csv("C:\\Users\\User\\github\\data\\TFTLCD\\ph1_bytime.csv", fileEncoding = 'CP949') # train
df2 = read.csv("C:\\Users\\User\\github\\data\\TFTLCD\\ph2_in.csv", fileEncoding = 'CP949') # normal test
df3 = read.csv("C:\\Users\\User\\github\\data\\TFTLCD\\ph2_out.csv", fileEncoding = 'CP949') # abnormal test
df_tr = df[,8:49] # 필요 정보만 select
df_te = df2[,8:49] # 필요 정보만 select
df_te_2 = df3[,8:49] # 필요 정보만 select
df2[df2$TOOL_NAME == 'P8TCVD060306','TOOL_NAME'] = 'Tool1'
df2[df2$TOOL_NAME == 'P8TCVD060307','TOOL_NAME'] = 'Tool2'
df2[df2$TOOL_NAME == 'P8TCVD060308','TOOL_NAME'] = 'Tool3'
df2[df2$TOOL_NAME == 'P8TCVD060309','TOOL_NAME'] = 'Tool4'
te = rbind(df_te, df_te_2)
all = rbind(df_tr, te)
all = cbind(df2[,1],all)
all = cbind(df2[,6],all)
head(all)
all = rename(all,c('df2[, 2]' = 'TOOL_NAME'))
all = rename(all,c('df2[, 6]' = 'TIME_STAMP'))
all
all = rename(all,c('df2[, 1]' = 'TOOL_NAME'))
write.csv(all,"C:\\Users\\User\\github\\data\\TFTLCD\\TFT_EDA_ALL.csv")
all
write.csv(all,"C:\\Users\\User\\github\\data\\TFTLCD\\TFT_EDA_ALL.csv")
train = df
test = te
## Tool로 구별
train1 = train[train$TOOL_NAME == 'Tool1', 9:50]
train2 = train[train$TOOL_NAME == 'Tool2', 9:50]
train3 = train[train$TOOL_NAME == 'Tool3', 9:50]
train4 = train[train$TOOL_NAME == 'Tool4', 9:50]
test1 = test[test$TOOL_NAME == 'P8TCVD060306', 9:50]
test
train
test = cbind(df2, df3)
test
test1 = test[test$TOOL_NAME == 'P8TCVD060306', 9:50]
test2 = test[test$TOOL_NAME == 'P8TCVD060307', 9:50]
test3 = test[test$TOOL_NAME == 'P8TCVD060308', 9:50]
test4 = test[test$TOOL_NAME == 'P8TCVD060309', 9:50]
## Isolation Forest
library(tidyverse)
library(dplyr)
library(solitude)
# training data로 학습
iforest1 = isolationForest$new()
iforest1$fit(train1)
iforest2 = isolationForest$new()
iforest2$fit(train2)
iforest3 = isolationForest$new()
iforest3$fit(train3)
iforest4 = isolationForest$new()
iforest4$fit(train4)
# training data로 학습
iforest1 = isolationForest(max_sample = 256)
iforest1$fit(train1)
# training data로 학습
iforest1 = isolation.forest
# training data로 학습
iforest1 = isolationForest$new()
iforest1$fit(train1)
iforest2 = isolationForest$new()
iforest2$fit(train2)
iforest3 = isolationForest$new()
iforest3$fit(train3)
iforest4 = isolationForest$new()
iforest4$fit(train4)
# 학습된 모델에 testing data 적용
preds1 = iforest1$predict(test1)
indices1 = preds1[which(preds1$anomaly_score > 0.6)]
preds2 = iforest2$predict(test2)
indices2 = preds2[which(preds2$anomaly_score > 0.6)]
# 학습된 모델에 testing data 적용
preds1 = iforest1$predict(test1)
source("~/카카오톡 받은 파일/Isolation Foreset.R", encoding = 'UTF-8', echo=TRUE)
source("~/카카오톡 받은 파일/Isolation Foreset.R", encoding = 'UTF-8', echo=TRUE)
# 학습된 모델에 testing data 적용
preds1 = iforest1$predict(test1)
iforest1
